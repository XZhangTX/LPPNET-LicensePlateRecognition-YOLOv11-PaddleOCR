---
<p align="center">
  ğŸŒ <b>Language:</b> English ğŸ‡¬ğŸ‡§ | ä¸­æ–‡ ğŸ‡¨ğŸ‡³
</p>

---

<details open>
<summary><b>English Version ğŸ‡¬ğŸ‡§</b></summary>
<h2>License Plate Recognition Based on YOLOv11 and PaddleOCR(åŸºäºyolov11ä¸ocrçš„è½¦ç‰Œè¯†åˆ«)</h2>

The license plate recognition project generally consists of two parts: localization and recognition. The common combination is YOLO+CRNN. This project directly utilizes PaddleOCR, eliminating the need for separate CRNN training. With YOLOv11's convenience and efficiency, it's extremely suitable for beginners to deploy directly. Training your own model is also straightforward.


only English version in README-EN.md

æœªæ¥å¯èƒ½ä¼šåŸºäºæ¨¡å‹æ€§èƒ½è¿›è¡Œè¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œä»¥åŠæ¢ç´¢å¯ä»¥å®ç°ç«¯åˆ°ç«¯çš„åŒæ—¶æ”¹è¿›çš„æ–¹å¼

In the future, further optimization may be based on model performance, as well as exploring ways to achieve simultaneous improvements in an end-to-end manner.

<h2>Deployment Process</h2>
<li>Environment Setup</li>

1. After setting up a virtual environment, you can directly install from the requirement.txt file in the package.
   
   \# Run the following code
   conda create -n \<your\_env\_name> python=3.10 #\<your\_env\_name> stands for the environment name, choose as you like; due to running YOLOv11, Python version should be 3.8 or above, this project uses 3.10
   conda activate \<your\_env\_name>
   cd path#path represents the project code location path
   pip install requirement.txt

1.2 You can also directly install ultralytics pillow tqdm opencv torch

<h2><li>Running the Project</li>
<h4>
1. Data Preparation</h4>

This project uses the CCPD2021 dataset for training, which is a yellow license plate dataset. If you want to increase the recognition range and categories, please refer to the training guide.

Dataset download: [CCPD Dataset](https://github.com/detectRecog/CCPD) |[CCPD2021 Yellow Plate Dataset](https://aistudio.baidu.com/datasetdetail/101671)

Additionally, the CCPD dataset does not have corresponding label files; its annotation information is all in the filenames. For YOLO training, there needs to be label files within the dataset. The ++/tools++ folder contains ++split.py++, which can extract bounding box positions from filenames into txt label files. This project also includes data labeled with labelimg suitable for YOLO, which can be found under the /data folder.

<h4>
2. Running Results</h4>

Before running, you need to modify the image paths under yaml first.

    #yolov11/cfg/datasets/car_plate.yaml
    #dataset path below
    #Modify the image data path here
    path: F:\LPPNET-LicensePlateRecognition-YOLOv11-PaddleOCR\car_plate # data path
    train: train/images  # train images
    val: val/images  # val images
    test: test/images  # test images

Run ++run.py++, the program will process the ++car\_plate++ data, results are saved under ++result++

    #In run file, you can modify input and output paths
    input_dir = "car_plate/test/img"
    output_dir = "car_plate/results"
    
æ¨¡å‹ç»“æœå¯ä»¥åœ¨runæ–‡ä»¶å¤¹ä¸‹çš„train13ä¸‹æ‰¾åˆ°ï¼Œä¸‹å›¾ä¸º<strong>æ··æ·†çŸ©é˜µ</strong>

<strong>confusionâ€”matrix</strong> as follow:
![image](https://github.com/user-attachments/assets/a6376a23-7d8b-460e-8df7-8e4b747da711)

<h2><li>Project Training</li></h2>

Run ++train.py++, the program will train the YOLOv11 model.
Parameters that can be changed in the model are as follows:

    if __name__ == '__main__':
        model = YOLO('yolov11/cfg/models/11/yolov11_plate.yaml')  # Specify the YOLO model object and load the model configuration from the specified configuration file
        model.load('yolo11n.pt')  # Load the pre-trained weight file 'yolov11s.pt' to accelerate training and improve model performance

        model.train(data='yolov11/cfg/datasets/car_plate.yaml',  # Specify the path to the training dataset configuration file, this .yaml file contains the dataset path and category information
                    cache=True,  # Whether to cache the dataset to speed up subsequent training, False means not caching
                    imgsz=300,  # Specify the image size used during training, 640 indicates resizing the input image to 640x640 pixels
                    epochs=200,  # Set the total number of training rounds to 200 rounds
                    batch=4,  # Set the batch size per training round to 16, i.e., use 16 images each time the model updates
                    close_mosaic=10,  # Set how many rounds before the end of training to turn off Mosaic data augmentation, 10 means turning off Mosaic in the last 10 rounds of training
                    workers=2,  # Set the number of threads used for data loading to 8, more threads can speed up data loading
                    patience=50,  # During training, if after 50 rounds there is no improvement in performance, stop training (early stopping mechanism)
                    device='cpu',  # Specify the device to use, '0' means using the first GPU for training
                    optimizer='SGD'  # Set the optimizer to SGD (Stochastic Gradient Descent), used for updating model parameters
                    )

If you want the project to recognize other types of license plates: prepare datasets of different kinds along with their respective yaml files. These files can be found under ++yolov11/cfg/datasets++ and ++yolov11/cfg/model++

<h2><li>References and Citations</li></h2>

Project References:
Github: <https://github.com/sirius-ai/LPRNet_Pytorch>
Githubï¼š<https://github.com/HuKai97/YOLOv5-LPRNet-Licence-Recognition.git>
YOLOï¼š<https://github.com/ultralytics/ultralytics.git>
</details>
<details open>
<summary><b>ä¸­æ–‡ç‰ˆ ğŸ‡¨ğŸ‡³</b></summary> <h2>åŸºäº YOLOv11 ä¸ PaddleOCR çš„è½¦ç‰Œè¯†åˆ«</h2>
<h2>
<p>License plate recognition based on YOLOv11 and paddleOCR<p>  
<p>åŸºäº<strong>YOLOv11ä¸<strong>PaddleOCRçš„è½¦ç‰Œè¯†åˆ«<p>
</h2>
è½¦ç‰Œè¯†åˆ«çš„é¡¹ç›®ä¸€èˆ¬ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œç¬¬ä¸€éƒ¨åˆ†æ˜¯å®šä½ï¼Œç¬¬äºŒéƒ¨åˆ†æ˜¯è¯†åˆ«ã€‚å¸¸ç”¨çš„ç»„åˆæ˜¯YOLO+CRNNï¼Œè¿™ä¸ªé¡¹ç›®ç›´æ¥è°ƒç”¨äº†PaddleOCRï¼Œä¸éœ€è¦å•ç‹¬è®­ç»ƒcrnnï¼ŒåŠ ä¹‹YOLOv11æ–¹ä¾¿å¿«æ·çš„å±æ€§ï¼Œæå…¶é€‚åˆå°ç™½ç›´æ¥éƒ¨ç½²ï¼Œæƒ³è¦è‡ªè¡Œè®­ç»ƒä¹Ÿå¾ˆç®€å•ã€‚

<h2>éƒ¨ç½²æµç¨‹<h2>
<li>ç¯å¢ƒæ­å»º</li></h2>

1.  æ­å»ºè™šæ‹Ÿç¯å¢ƒåå¯ä»¥ç›´æ¥å®‰è£…æ–‡ä»¶ä¸­çš„requirement.txt

<!---->

    #è¿è¡Œä»¥ä¸‹ä»£ç 
    conda create -n <your_env_name> python=3.10 #<your_env_name>æ˜¯ç¯å¢ƒåï¼Œè‡ªè¡Œé€‰æ‹©ï¼›pythonç‰ˆæœ¬ç”±äºæ˜¯è¿è¡Œyolov11ï¼Œéœ€è¦åœ¨3.8åŠå…¶ä¹‹ä¸Šï¼Œæœ¬é¡¹ç›®é€‰ç”¨3.10
    conda activate <your_env_name>
    cd path#path æ˜¯é¡¹ç›®ä»£ç æ‰€åœ¨è·¯å¾„
    pip install requirement.txt

1.2 ä¹Ÿå¯ç›´æ¥å®‰è£…ultralytics pillow tqdm opencv torch

<h2><li>é¡¹ç›®è¿è¡Œ</li>
<h4>
1.æ•°æ®å‡†å¤‡</h4>

æœ¬é¡¹ç›®ä½¿ç”¨CCPD2021æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œè¯¥æ•°æ®é›†æ˜¯é»„è‰²è½¦ç‰Œæ•°æ®é›†ã€‚æƒ³è¦å¢åŠ è¯†åˆ«èŒƒå›´ä¸ç±»åˆ«çš„å°ä¼™ä¼´å¯ä»¥çœ‹è®­ç»ƒæŒ‡å¼•ã€‚

æ•°æ®é›†ä¸‹è½½å‰å¾€[ï¼šCCPDæ•°æ®é›†](https://github.com/detectRecog/CCPD) |[CCPD2021é»„ç‰Œæ•°æ®é›†](https://aistudio.baidu.com/datasetdetail/101671)

å¦å¤–ï¼šCCPDæ•°æ®é›†æ²¡æœ‰ç›¸åº”çš„labelæ–‡ä»¶ï¼Œå…¶æ ‡æ³¨ä¿¡æ¯å‡åœ¨æ–‡ä»¶åä¸Šï¼Œå¯¹äºyoloè®­ç»ƒï¼Œæ•°æ®é›†ä¸­æ˜¯è¦æœ‰labelæ–‡ä»¶çš„ï¼Œ++/tools++æ–‡ä»¶å¤¹ä¸­å‡†å¤‡äº†++split.py++å¯ä»¥å°†æ–‡ä»¶åä¸­çš„è¯†åˆ«æ¡†ä½ç½®æå–æˆtxtçš„labelæ–‡ä»¶ã€‚
æœ¬é¡¹ç›®ä¹Ÿå‡†å¤‡äº†ç»è¿‡labelimgæ ‡æ³¨è¿‡çš„é€‚ç”¨äºyoloçš„æ•°æ®é›†ï¼Œå¯ä»¥åœ¨/dataæ–‡ä»¶å¤¹ä¸‹æ‰¾åˆ°

<h4>
2.è¿è¡Œç»“æœ</h4>

è¿è¡Œå‰ï¼Œéœ€è¦å…ˆä¿®æ”¹yamlä¸‹çš„å›¾åƒè·¯å¾„

    #yolov11/cfg/datasets/car_plate.yaml
    #datasetä¸‹çš„æ•°æ®è·¯å¾„
    #æ­¤å¤„ä¿®æ”¹å›¾åƒæ•°æ®è·¯å¾„
    path: F:\LPPNET-LicensePlateRecognition-YOLOv11-PaddleOCR\car_plate # data path
    train: train/images  # train images
    val: val/images  # val images
    test: test/images  # test images

è¿è¡Œ++run.py++,ç¨‹åºä¼šå¤„ç†++car\_plate++ä¸‹çš„æ•°æ®ï¼Œç»“æœä¿å­˜åœ¨++result++ä¸‹

    #runæ–‡ä»¶ä¸‹å¯ä»¥ä¿®æ”¹è¾“å…¥ä»¥åŠè¾“å‡ºè·¯å¾„
    input_dir = "car_plate/test/img"
    output_dir = "car_plate/results"

<h2><li>é¡¹ç›®è®­ç»ƒ</li></h2>

è¿è¡Œ++train.py++ï¼Œç¨‹åºä¼šè®­ç»ƒyolov11æ¨¡å‹
æ¨¡å‹å¯ä»¥æ›´æ”¹çš„å‚æ•°å¦‚ä¸‹ï¼š

    if __name__ == '__main__':
        model = YOLO('yolov11/cfg/models/11/yolov11_plate.yaml')  # æŒ‡å®šYOLOæ¨¡å‹å¯¹è±¡ï¼Œå¹¶åŠ è½½æŒ‡å®šé…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹é…ç½®
        model.load('yolo11n.pt')  # åŠ è½½é¢„è®­ç»ƒçš„æƒé‡æ–‡ä»¶'yolov11s.pt'ï¼ŒåŠ é€Ÿè®­ç»ƒå¹¶æå‡æ¨¡å‹æ€§èƒ½

        model.train(data='yolov11/cfg/datasets/car_plate.yaml',  # æŒ‡å®šè®­ç»ƒæ•°æ®é›†çš„é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œè¿™ä¸ª.yamlæ–‡ä»¶åŒ…å«äº†æ•°æ®é›†çš„è·¯å¾„å’Œç±»åˆ«ä¿¡æ¯
                    cache=True,  # æ˜¯å¦ç¼“å­˜æ•°æ®é›†ä»¥åŠ å¿«åç»­è®­ç»ƒé€Ÿåº¦ï¼ŒFalseè¡¨ç¤ºä¸ç¼“å­˜
                    imgsz=300,  # æŒ‡å®šè®­ç»ƒæ—¶ä½¿ç”¨çš„å›¾åƒå°ºå¯¸ï¼Œ640è¡¨ç¤ºå°†è¾“å…¥å›¾åƒè°ƒæ•´ä¸º640x640åƒç´ 
                    epochs=200,  # è®¾ç½®è®­ç»ƒçš„æ€»è½®æ•°ä¸º200è½®
                    batch=4,  # è®¾ç½®æ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡çš„å¤§å°ä¸º16ï¼Œå³æ¯æ¬¡æ›´æ–°æ¨¡å‹æ—¶ä½¿ç”¨16å¼ å›¾ç‰‡
                    close_mosaic=10,  # è®¾ç½®åœ¨è®­ç»ƒç»“æŸå‰å¤šå°‘è½®å…³é—­ Mosaic æ•°æ®å¢å¼ºï¼Œ10 è¡¨ç¤ºåœ¨è®­ç»ƒçš„æœ€å 10 è½®ä¸­å…³é—­ Mosaic
                    workers=2,  # è®¾ç½®ç”¨äºæ•°æ®åŠ è½½çš„çº¿ç¨‹æ•°ä¸º8ï¼Œæ›´å¤šçº¿ç¨‹å¯ä»¥åŠ å¿«æ•°æ®åŠ è½½é€Ÿåº¦
                    patience=50,  # åœ¨è®­ç»ƒæ—¶ï¼Œå¦‚æœç»è¿‡50è½®æ€§èƒ½æ²¡æœ‰æå‡ï¼Œåˆ™åœæ­¢è®­ç»ƒï¼ˆæ—©åœæœºåˆ¶ï¼‰
                    device='cpu',  # æŒ‡å®šä½¿ç”¨çš„è®¾å¤‡ï¼Œ'0'è¡¨ç¤ºä½¿ç”¨ç¬¬ä¸€å—GPUè¿›è¡Œè®­ç»ƒ
                    optimizer='SGD'  # è®¾ç½®ä¼˜åŒ–å™¨ä¸ºSGDï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰ï¼Œç”¨äºæ¨¡å‹å‚æ•°æ›´æ–°
                    )

å¦‚æœæƒ³è®©é¡¹ç›®å¯ä»¥è¯†åˆ«å…¶ä»–ç§ç±»çš„è½¦ç‰Œï¼šéœ€è¦å‡†å¤‡ä¸åŒç§ç±»çš„æ•°æ®é›†ä»¥åŠç›¸åº”çš„yamlæ–‡ä»¶ï¼Œè¯¥é¡¹ç›®çš„æ–‡ä»¶å¯ä»¥åœ¨++yolov11/cfg/datasets++ä»¥åŠ++yolov11/cfg/model++ä¸‹æ‰¾åˆ°

<h2><li>å‚è€ƒåŠå¼•ç”¨</li></h2>

é¡¹ç›®å‚è€ƒ
Github: <https://github.com/sirius-ai/LPRNet_Pytorch>
Githubï¼š<https://github.com/HuKai97/YOLOv5-LPRNet-Licence-Recognition.git>
YOLOï¼š<https://github.com/ultralytics/ultralytics.git>
</details>

